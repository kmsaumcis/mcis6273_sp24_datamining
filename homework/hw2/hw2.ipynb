{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["\\begin{center}\n", "\\begin{huge}\n", "MCIS6273 Data Mining (Prof. Maull) / Spring 2024 / HW2\n", "\\end{huge}\n", "\\end{center}\n", "\n", "| Points <br/>Possible | Due Date | Time Commitment <br/>(estimated) |\n", "|:---------------:|:--------:|:---------------:|\n", "| 30 | Wednesday April 24 @ Midnight | _up to_ 24 hours |\n", "\n", "\n", "* **GRADING:** Grading will be aligned with the completeness of the objectives.\n", "\n", "* **INDEPENDENT WORK:** Copying, cheating, plagiarism  and academic dishonesty _are not tolerated_ by University or course policy.  Please see the syllabus for the full departmental and University statement on the academic code of honor.\n", "\n", "## OBJECTIVES\n", "* Perfom basic data engineering, visualization and data analysis in Python using an external set data.\n", "\n", "* Use GeoPandas analyze and map datasets\n", "\n", "* Perform clustering using Gaussian Mixture Model (EM) in SciKit-Learn\n", "\n", "* Complete the online HW assessment.\n", "\n", "## WHAT TO TURN IN\n", "You are being encouraged to turn the assignment in using the provided\n", "Jupyter Notebook.  To do so, make a directory in your Lab environment called\n", "`homework/hwX`.   Put all of your files in that directory.  Then zip or tar that directory,\n", "rename it with your name as the first part of the filename (e.g. `maull_HWX_files.zip`, `maull_HWX_files.tar.gz`), then\n", "download it to your local machine, then upload the `.zip` to Blackboard.\n", "\n", "If you do not know how to do this, please ask, or visit one of the many tutorials out there\n", "on the basics of using zip in Linux.\n", "\n", "If you choose not to use the provided notebook, you will still need to turn in a\n", "`.ipynb` Jupyter Notebook and corresponding files according to the instructions in\n", "this homework.\n", "\n", "\n", "## ASSIGNMENT TASKS\n", "### (20%) Perfom basic data engineering, visualization and data analysis in Python using an external set data. \n", "\n", "As usual, we will continue the practice of data engineering to\n", "prepare data for analysis.  \n", "\n", "This time, we will use two different open datasets and along the way learn\n", "some new tools that will be valuable in our analysis and data \n", "mining toolkit.\n", "\n", "For this particular assigment, we will _pretend that we are data scientists who\n", "have been hired \n", "to understand the electronic vehicle (EV) market_ in the state of Minnesota.\n", "\n", "We have been given a dataset of all the registrations of EVs in the state\n", "since 2010.  You will need to obtain this dataset from here:\n", "\n", "* [State EV Registration Download (Atlas EVHUB)](https://www.atlasevhub.com/materials/state-ev-registration-data/#data)\n", "* Direct link to CSV file: [MN_EV_Registrations.csv](https://www.atlasevhub.com/public/dmv/MN_EV_Registrations.csv)\n", "\n", "And you will be asked to first run some basic statistics over it, then\n", "merge it with other data for further analysis. You should explore the\n", "website a bit and understand the data columns (there aren't many).\n", "\n", "As before, all of your code must be implemented in Jupyter as a notebook -- you\n", "will be required to turn in a **working** `.ipynb` file.\n", "\n", "**&#167; Task:**  **Use Python to obtain and prepare data.**\n", "\n", "* Load the _original_ file and save the CSV to a folder called `\"data/\"`.\n", "\n", "\n", "**&#167; Task:**  **Transform, filter and store the data as a new CSV**\n", "\n", "* Create a new column called \"`registration_year`\", to represent the registration year.  \n", "  You will find [`pandas.to_datetime()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) on the `Registration Date` column\n", "  to be useful. You will need to strip the date for just the year \n", "  (see [`.dt`](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.html)).\n", "\n", "* Drop any \"`Vehicle Make`\" which did not sell more than 100 cars over the entire time \n", "frame of the date.  **HINT**: There are 22 makes and a total of 455 rows of data which \n", "will be removed.  You will end up with about 367.6k rows of final data.\n", "\n", "* Filter the columns to just the set : `'ZIP Code',  'Vehicle Make', 'Vehicle Model', 'registration_year', 'Vehicle Model Year'`\n", "\n", "* Store the final file in the `\"data/\"` folder and name it \"`FILTERED_MN_EV_Registrations.csv`\".\n", "\n", "\n", "**&#167; Task:**  **Plot the data using a Bar graph**\n", "\n", "* Using a bar graph, plot the frequency of registrations by year.  That is \n", "the $x$-axis will contain the year, and $y$-axis the frequency.\n", "\n", "\n", "**&#167; Task:**  **React to the following statements:**\n", "\n", "* The largest number of _new_ registrations was in 2023.\n", "* The number of new registrations slowed in 2019.\n", "\n", "Use evidence to support your reactions!\n", "\n", "**NOTE:** Assume a car needs to be registered each year, so the data is cummulative.\n", "\n", "\n", "\n", "### (30%) Use GeoPandas analyze and map datasets \n", "\n", "We have been using Pandas for most of our work, and in \n", "general it is the data manipuation workhorse of our \n", "data science workflows.  Interestingly, there are \n", "other libraries which you will run across that can\n", "do things Pandas cannot do, and while we're not going\n", "to get into large enough datasets in this assigment,\n", "you will well to learn about Dask, Datatable and Vaex.\n", "\n", "We will turn our attention, however, to an area\n", "of great interest in data science and analytics:\n", "geospatial data.  We are all familiar with the \n", "basic visualizations of US maps showing the incidence\n", "of poverty, crime, income or any host of demographic\n", "information. Nearly all of these types of maps\n", "use specialized data formats which encode the \n", "geospatial details of the underlying data so\n", "that you don't have to.\n", "\n", "One especially significant format in this GIS or\n", "Geographic Information Systems space is called\n", "\"Shapefiles\" or \".shp\" files.  Without going \n", "into too much detail, these files can encode not\n", "only the geospatial information (coordinates, polygons\n", "representing areas, etc), they can store \n", "underlying data such as demographic information\n", "or nearly anything else.\n", "\n", "Learn about GIS and SHP files here:\n", "\n", "* [ESRI.com | \"What is GIS?\"](https://www.esri.com/en-us/what-is-gis/overview)\n", "* [gisresources.com | \"Understanding Shapefile File Format\"](https://gisresources.com/understanding-shapefile-shp-file-format/)\n", "* [wiki.gis.com | Shapefile](https://wiki.gis.com/wiki/index.php/Shapefile)\n", "\n", "In Python, working with Shapefiles occurs through a \n", "number of libraries, but the one important to this assignment\n", "is GeoPandas.  Learn about it here:\n", "\n", "* [GeoPandas](https://geopandas.org/en/stable/#)\n", "\n", "This particular library is beyond cool and can do \n", "amazing things with very little code, and we are going to do \n", "just that.\n", "\n", "In this next part of the assignment, we are going \n", "to use GeoPandas to show information about the demographics\n", "of Minnesota ZIP Codes.  \n", "\n", "Before we begin, we might be asking ourselves, why?  Weren't we talking\n", "about EVs before and what does this have to do with \n", "working as pretend data scientists to understand the EV market?\n", "\n", "Often, to understand the dynamics of new technology, and \n", "especially technology which requires significant financial\n", "investment, it is important to understand the details of \n", "who might be buying these items, and often it is not as easy\n", "as looking at a single dataset containing all required data. \n", "We will usually need to combine data from multiple sources to get at\n", "some of the questions we have.\n", "\n", "Some of the questions being asked of the pretend data science \n", "team are the following:\n", "\n", "* What is the frequency of and association within the ZIP\n", "  codes of EV registration in Minnesota?\n", "* Are there demographic patterns in these ZIP codes?\n", "* Can we visualize these inquiries?\n", "\n", "Before we continue, let's first ask, what do ZIP codes have to\n", "do with anything? There are many aspects of US ZIP codes which might\n", "surprise you.  Social, economic and health scientists have uncovered\n", "staggering relationships between ZIP codes amd income, education, health outcomes,\n", "crime, etc., for example see the sample of these papers:\n", "\n", "* Gobaud, Ariana N., et al. \u201cAbsolute versus Relative Socioeconomic Disadvantage and Homicide: A Spatial Ecological Case\u2013Control Study of US Zip Codes.\u201d Injury Epidemiology, vol. 9, no. 1, Feb. 2022, p. 7. DOI.org (Crossref), [https://doi.org/10.1186/s40621-022-00371-z](https://doi.org/10.1186/s40621-022-00371-z).\n", "* Nguyen, Quynh C., et al. \u201cTwitter-Derived Neighborhood Characteristics Associated with Obesity and Diabetes.\u201d Scientific Reports, vol. 7, no. 1, Nov. 2017, p. 16425. DOI.org (Crossref), [https://doi.org/10.1038/s41598-017-16573-1](https://doi.org/10.1038/s41598-017-16573-1).\n", "* Thomas, Avis J., et al. \u201cZIP-Code-Based versus Tract-Based Income Measures as Long-Term Risk-Adjusted Mortality Predictors.\u201d American Journal of Epidemiology, vol. 164, no. 6, Sept. 2006, pp. 586\u201390. DOI.org (Crossref), [https://doi.org/10.1093/aje/kwj234](https://doi.org/10.1093/aje/kwj234).\n", "\n", "These are but a short list of what you will find in the research. On to the task at hand ...\n", "\n", "We will be gathering demographic data from the _American Community Survey (ACS)_\n", "which gathers data about US demographics.  We will use the latest survey data\n", "tethered to the 2020 Census, which covers 2016-2020.\n", "\n", "**NOTE:** You will need to install `GeoPandas`, `folium` and `mapclassify` at the top of your notebook -- they are **not** installed\n", "in the default environment on our Hub.  Use :\n", "\n", "```bash\n", "  !pip install geopandas mapclassify folium\n", "```\n", "\n", "to install the required libraries.\n", "\n", "**&#167; Task:**  **Load the Shapefile from the Minnesota ACS**\n", "\n", "You will find the main dataset here:\n", "\n", "* [https://gisdata.mn.gov/dataset/us-mn-state-metc-society-census-acs](https://gisdata.mn.gov/dataset/us-mn-state-metc-society-census-acs)\n", "\n", "The ZIP file can be downloaded directly from here:\n", "\n", "* [https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/society_census_acs/shp_society_census_acs.zip](https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/society_census_acs/shp_society_census_acs.zip)\n", "\n", "**NOTE:** You will unzip the file into a folder called \"`acs/`\" and load the file containing ZIP Code demographic summaries: `CensusACSZipCode.dbf`.\n", "\n", "\n", "**&#167; Task:**  **Build a map of the ZIP Census Tract Areas (ZCTA)**\n", "\n", "This can be accomplished with [`.plot()`](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.plot.html)\n", "\n", "\n", "**&#167; Task:**  **Explore variables in the data**\n", "\n", "You will need to study the data fields that you have now loaded.\n", "\n", "\n", "See this for more information on what each column name means:\n", "\n", "* [https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/society_census_acs/metadata/metadata.html](https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_metc/society_census_acs/metadata/metadata.html)\n", "\n", "Answer the following questions:\n", "\n", "1. What is the mean Houshold Income (`MEDIANHHI`) in the dataset?\n", "2. How does this compare with the median HHI for the entire US in 2020? (You will need to find that yourself.)\n", "3. Which ZIP code has the highest HHI?\n", "4. What are the top 5 ZIP codes with the largest percent population under 18 years of age? (You \n", "   will need to remember to use the total population of the ZIP as the denomenator for each ZIP.)\n", "5. Which 5 ZIP codes have the highest percent of professional / graduate degrees?\n", "\n", "\n", "**&#167; Task:**  **Plot an interactive demographics map of ZIP codes with high value homes**\n", "\n", "Use the ACS data to show the ZIP codes with homes greater than 0.5M (500K).  You will need to do the following:\n", "\n", "1. Filter the data to the homes with value > 500 (in the ACS data)\n", "2. Aggregate those and use `VAL_DENOM` as the denomenator to get a percentage\n", "3. Add the calculated field to the filtered GeoDataFrame\n", "4. Run the [`GeoDataFrame.explore()`](https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoDataFrame.explore.html) function on the dataset \n", "\n", "Your output will look something like this (but with colored ZCTAs indicating the high value homes ZCTA):\n", "\n", "![](./gpd_explore_example.png)\n", "\n", "\n", "**&#167; Task:**  **Plot demographics and EV**\n", "\n", "You will now take your EV dataset from the first part and analyze it with the ACS data.\n", "\n", "You will find that GeoPandas works just like Pandas in allowing for operations on\n", "DataFrames.\n", "\n", "You will take the EV data and merge it with eht ACS data, and make the following plots:\n", "\n", "1. plot (using GeoPandas `plot()`) `MEDIANHHI`  using the ZCTA\n", "2. plot (using GeoPandas `plot()`) `HOMEOWNPCT` using the ZCTA\n", "3. create a correlation matrix of `MEDIANHHI ` and `ev_count` for all ZIP codes \n", "4. plot an interactive plot (using `explore()`) of the correlation; to do this\n", "   you will need to find the correlation for all ZIP codes then\n", "   merge these back into the GeoDataFrame.\n", "\n", "\n", "\n", "### (25%) Perform clustering using Gaussian Mixture Model (EM) in SciKit-Learn \n", "\n", "In lecture, we learned about GMMs or the Expectation Maximization\n", "algorithm.\n", "\n", "Again, you should become familiar with the algorithm and implementation in ScikitLearn:\n", "\n", "* [sklearn.mixture.GaussianMixture](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html)\n", "\n", "In this part we will explore three variations to clustering:\n", "\n", "* **varation 1:** _cluster based on a pre-defined set of features_\n", "* **varation 2:** _cluster based on a high variance features_\n", "* **varation 1:** _cluster based on all  features_\n", "\n", "Usually in clustering, we will need to set the number of clusters\n", "ahead of time.  To simplify things, we will only seek three\n", "cluster sizes, 5, 9 and 12.  These are arbitrary for now and \n", "in a bonus opportunity, you will use other methods to \n", "find optimal cluster sizes.\n", "\n", "**&#167; Task:**  **Use the GMM algorithm to cluster the data with pre-defined features**\n", "\n", "You will use GMM to cluster, but you will only use the following features:\n", "\n", "* `HIGHSCHOOL, SOMECOLLEG, ASSOCIATE, BACHELORS, GRADPROF, R300_399, R400_499, R500_599, \n", "R600_699, R700_799, R800_899, R900_999, R1000_1249, R1250_1499, R1500_1999, R2000up, \n", "VAL40_69, VAL70_99, VAL100_124, VAL125_149, VAL150_174, VAL175_199, VAL200_249, \n", "VAL250_299, VAL300_399, VAL400_499, VAL500_749, VAL750_999, VAL1MIL, MEDIANHHI, \n", "AGEUNDER18, AGE18_39, AGE40_64, AGE65UP, LIVEDALONE, MARRKIDS, UNMARRKIDS, FAMNOKIDS, \n", "NONFAMILY, POPTOTAL`\n", "\n", "You might notice these features seem to be around demographic features: income,\n", "homeownership, etc.\n", "\n", "Complete the following:\n", "\n", "1. Perform the clustering with `n_components=` 5, 9 and 12 (each will be a separate run).\n", "2. **Only for the `n_components=5` cluster**, describe each cluster in real words.  Bring attention to which \n", "   features seem to dominate the cluster.\n", "3. Make an interactive plot using the ZIP codes in each cluster for the `n_components=5` and `n_components=12` clusters. This \n", "   will require you to get ZIP codes of each cluster, assign them a label, add that label to each of\n", "   the ZIP codes in the original GeoPandas DataFrame, then execute `plot()`.  Amazingly, the function\n", "   will do all the hard work of coloring those clusters for you as long as the labels are distinct.\n", "   **NOTE:** the ZIP Code is hiding out in the `GEOG_UNIT` feature, so you will need to match each\n", "   data point with the cluster it belongs to, then get the `GEOG_UNIT`, assign a label, then plot.  There\n", "   is a little work involved in this.\n", "\n", "\n", "**&#167; Task:**  **Use the GMM algorithm to cluster the high variance features**\n", "\n", "Often, we have too many features to manually select as we did in the prior task.  Instead,\n", "we can perform a simple removal of features with low variance.  The idea behind\n", "this is that low variance features do not contribute much to the overall shape of the data,\n", "so when determining which features would truly make a difference in clustering, they\n", "can often be removed with much effect.\n", "\n", "* study the [`sklearn.feature_selection.VarianceThreshold`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html#sklearn.feature_selection.VarianceThreshold)\n", "\n", "1. Use `VarianceThreshold` on the entire dataset to eleminate features. set `threshold=0.4`\n", "2. Perform GMM as before, this time with just `n_components=5`\n", "3. Make an interactive plot as before, compare this plot with the previous with a 2-3 \n", "   sentence summary of the differences.\n", "\n", "\n", "**&#167; Task:**  **Use the GMM algorithm to cluster all features**\n", "\n", "Usually, the full feature set will not be easily accomplished since the amount of memory resources\n", "is rather high.\n", "\n", "1. Perform clustering with `n_components=5`.\n", "2. It is possible that the system will crash.  If it does, please report this and leave the notebook \n", "   in the crashed state for this cell.\n", "\n", "\n", "\n", "### (20%) Complete the online HW assessment. \n", "\n", "\n", "Once you are done with the coding part of the assignment, you will need to \n", "complete the online assessment for\n", "the final **6 (20%) points of your grade** for this assignment.\n", "\n", "**&#167; Task:**  **Go to the course Blackboard and complete the assessment.**\n", "\n", "\n", "\n"]}], "metadata": {"anaconda-cloud": {}, "kernelspec": {"display_name": "Python [default]", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.1"}, "toc": {"colors": {"hover_highlight": "#DAA520", "navigate_num": "#000000", "navigate_text": "#333333", "running_highlight": "#FF0000", "selected_highlight": "#FFD700", "sidebar_border": "#EEEEEE", "wrapper_background": "#FFFFFF"}, "moveMenuLeft": true, "nav_menu": {"height": "12px", "width": "252px"}, "navigate_menu": true, "number_sections": false, "sideBar": true, "threshold": "1", "toc_cell": false, "toc_section_display": "block", "toc_window_display": true, "widenNotebook": false}}, "nbformat": 4, "nbformat_minor": 0}